{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "import torchsummary\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/api-key.json\") as key:\n",
    "    wandb.login(key=json.load(key)['wandb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10(Dataset):\n",
    "    def __init__(self, path, train=True, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "        if train:\n",
    "            for i in range(1, 6):\n",
    "                data = self.unpickle(path + f\"/data_batch_{i}\")\n",
    "                images.append(data[b\"data\"].reshape(-1, 3, 32, 32))\n",
    "                labels.append(data[b\"labels\"])\n",
    "            self.images = np.concatenate(images).transpose((0, 2, 3, 1))\n",
    "            self.labels = np.concatenate(labels)\n",
    "        else:\n",
    "            data = self.unpickle(path + f\"/test_batch\")\n",
    "            self.images = data[b\"data\"].reshape(-1, 3, 32, 32).transpose((0, 2, 3, 1))\n",
    "            self.labels = data[b\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images = self.images[index]\n",
    "        lables = self.labels[index]\n",
    "        if self.transform is not None:\n",
    "            images = self.transform(images)\n",
    "        return images, lables\n",
    "    \n",
    "    def unpickle(self, path):\n",
    "        import pickle\n",
    "        with open(path, 'rb') as fo:\n",
    "            data = pickle.load(fo, encoding='bytes')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(128*28*28, 10)\n",
    "        # self.fc = nn.LazyLinear(10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 30, 30]           1,792\n",
      "              ReLU-2           [-1, 64, 30, 30]               0\n",
      "            Conv2d-3          [-1, 128, 28, 28]          73,856\n",
      "              ReLU-4          [-1, 128, 28, 28]               0\n",
      "           Flatten-5               [-1, 100352]               0\n",
      "            Linear-6                   [-1, 10]       1,003,530\n",
      "================================================================\n",
      "Total params: 1,079,178\n",
      "Trainable params: 1,079,178\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.18\n",
      "Params size (MB): 4.12\n",
      "Estimated Total Size (MB): 7.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "testmodel = Net()\n",
    "torchsummary.summary(testmodel, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:f2qaps84) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▂▂▃▃▄▄▅▅▅▅▆▆▆▇▆▇▇▇▇█▇████████</td></tr><tr><td>loss</td><td>█▇▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>56.42971</td></tr><tr><td>loss</td><td>1.14221</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-cloud-14</strong> at: <a href='https://wandb.ai/jemin/study/runs/f2qaps84' target=\"_blank\">https://wandb.ai/jemin/study/runs/f2qaps84</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230320_174016-f2qaps84/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:f2qaps84). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jemin/vscode/BoostCamp/Week2/Study/wandb/run-20230320_184204-vfuzq0yc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jemin/study/runs/vfuzq0yc' target=\"_blank\">ethereal-haze-15</a></strong> to <a href='https://wandb.ai/jemin/study' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jemin/study' target=\"_blank\">https://wandb.ai/jemin/study</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jemin/study/runs/vfuzq0yc' target=\"_blank\">https://wandb.ai/jemin/study/runs/vfuzq0yc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jemin/study/runs/vfuzq0yc?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15f11e680>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 30\n",
    "}\n",
    "wandb.init(project=\"study\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_dataset = Cifar10(path=\"../../data/cifar-10-batches-py\", train=True, transform=transforms.ToTensor())\n",
    "test_dataset = Cifar10(path=\"../../data/cifar-10-batches-py\", train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataset, valid_dataset = random_split(train_valid_dataset, [40000, 10000])\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, valid_dataloader, model, criterion, optimizer, config):\n",
    "    for epoch in range(1, config[\"epochs\"] + 1):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for image, label in train_dataloader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = 0\n",
    "            model.eval()\n",
    "            for image, label in valid_dataloader:\n",
    "                image, label = image.to(device), label.cpu()\n",
    "                pred = model(image).cpu()\n",
    "                acc += (pred.argmax(1) == label).float().sum().item()\n",
    "        \n",
    "        print(f\"epoch: {epoch:3}, loss: {epoch_loss / len(train_dataloader):3f}, acc: {acc / len(test_loader) / config['batch_size'] * 100:.2f}%\")\n",
    "        wandb.log({\n",
    "            \"loss\": epoch_loss / len(train_dataloader),\n",
    "            \"acc\": acc / len(test_loader) / config[\"batch_size\"] * 100\n",
    "            })\n",
    "        tune.report(acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, device):\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        model.eval()\n",
    "        for image, label in dataloader:\n",
    "            image, label = image.to(device), label.cpu()\n",
    "            pred = model(image).cpu()\n",
    "            acc += (pred.argmax(1) == label).float().sum().item()\n",
    "        print(f\"acc: {acc / len(test_loader) / config['batch_size'] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp(config):\n",
    "    train_valid_dataset = Cifar10(path=\"../../data/cifar-10-batches-py\", train=True, transform=transforms.ToTensor())\n",
    "\n",
    "    train_dataset, valid_dataset = random_split(train_valid_dataset, [40000, 10000])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "    train(train_loader, valid_loader, model, criterion, optimizer, config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10 ** (-10 * np.random.rand())),\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10\n",
    "}\n",
    "tunner = tune.Tuner(temp, param_space=search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config, checkpoint_dir, data_dir):\n",
    "    train_valid_dataset = Cifar10(path=\"../../data/cifar-10-batches-py\", train=True, transform=transforms.ToTensor())\n",
    "    test_dataset = Cifar10(path=\"../../data/cifar-10-batches-py\", train=False, transform=transforms.ToTensor()) \n",
    "\n",
    "    train_dataset, valid_dataset = random_split(train_valid_dataset, [40000, 10000])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)  \n",
    "\n",
    "    model = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1, loss: 2.059463, acc: 33.82%\n",
      "epoch:   2, loss: 1.865511, acc: 36.72%\n",
      "epoch:   3, loss: 1.781011, acc: 38.66%\n",
      "epoch:   4, loss: 1.719234, acc: 40.85%\n",
      "epoch:   5, loss: 1.669013, acc: 41.22%\n",
      "epoch:   6, loss: 1.624945, acc: 44.56%\n",
      "epoch:   7, loss: 1.584314, acc: 44.28%\n",
      "epoch:   8, loss: 1.547626, acc: 45.46%\n",
      "epoch:   9, loss: 1.513358, acc: 47.04%\n",
      "epoch:  10, loss: 1.481849, acc: 47.63%\n",
      "epoch:  11, loss: 1.453779, acc: 48.05%\n",
      "epoch:  12, loss: 1.428120, acc: 49.56%\n",
      "epoch:  13, loss: 1.403040, acc: 49.17%\n",
      "epoch:  14, loss: 1.380928, acc: 50.42%\n",
      "epoch:  15, loss: 1.358372, acc: 51.97%\n",
      "epoch:  16, loss: 1.336970, acc: 50.11%\n",
      "epoch:  17, loss: 1.315795, acc: 53.12%\n",
      "epoch:  18, loss: 1.297201, acc: 53.37%\n",
      "epoch:  19, loss: 1.279061, acc: 54.19%\n",
      "epoch:  20, loss: 1.261036, acc: 53.42%\n",
      "epoch:  21, loss: 1.246961, acc: 54.94%\n",
      "epoch:  22, loss: 1.230391, acc: 54.85%\n",
      "epoch:  23, loss: 1.218494, acc: 55.10%\n",
      "epoch:  24, loss: 1.207496, acc: 55.60%\n",
      "epoch:  25, loss: 1.194753, acc: 56.17%\n",
      "epoch:  26, loss: 1.183753, acc: 55.56%\n",
      "epoch:  27, loss: 1.173131, acc: 55.55%\n",
      "epoch:  28, loss: 1.161994, acc: 56.39%\n",
      "epoch:  29, loss: 1.151546, acc: 56.50%\n",
      "epoch:  30, loss: 1.142209, acc: 56.43%\n",
      "acc: 56.86%\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, valid_loader, model, criterion, optimizer, device, config[\"epochs\"])\n",
    "test(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
